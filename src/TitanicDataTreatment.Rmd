---
title: "PRA2"
output: html_document
date: '2022-05-16'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


Instalamos y cargamos las librerías.
```{r warning=FALSE, message=FALSE}
# https://cran.r-project.org/web/packages/ggplot2/index.html
if (!require('ggplot2')) install.packages('ggplot2'); library('ggplot2')
# https://cran.r-project.org/web/packages/dplyr/index.html
if (!require('dplyr')) install.packages('dplyr'); library('dplyr')
if (!require('caret')) install.packages('caret'); library('caret')
if (!require('normtest')) install.packages('normtest'); library('normtest')
if (!require('car')) install.packages('car'); library('car')
if (!require('gridExtra')) install.packages('gridExtra'); library('gridExtra')
```


## Ejercicio 1

Descripción del dataset. ¿Por qué es importante y qué pregunta/problema pretende
responder?

### 1.1 Carga de los datos

Cargamos el dataset.
```{r}
df <- read.csv('../data/train.csv',stringsAsFactors = FALSE)
```


Confirmamos que el dataset se ha cargado correctamente:
```{r}
head(df)
```

### 1.2 Descripción del dataset

Descripción del dataset:
```{r}
str(df)
```

Observamos que el conjunto de datos consta de 891 observaciones y 12 variables que describen la tripulación del Titanic.

**PassengerId**
    Número identificador del pasajero (Integer).
    
**Survived**
    Variable que especifica si un pasajero ha sobrevivido. 0 = No, 1 = Si (Integer).
    
**Pclass**
    Clase socio económica del pasajero. 1 = Clase Alta, 2 = Clase Media, 3 = Clase baja (Integer).
    
**Name**
    Nombre del pasajero (String).
    
**Sex**
    Sexo del pasajero (String).
    
**Age**
    Edad del pasajero. Para pasajeros de menos de un año, la edad esta fraccionada. Si la edad esta estimada, su formato es xx.5 (Numeric).

**SibSp**
    Número de familiares, hermanos o esposos, a abordo (Integer).
    
**Parch**
    Número de familiares, padres o hijos, a bordo (Ingeger).
    
**Ticket**
    Número del billete (String).
    
**Fare**
    Precio del billete (Numeric).
    
**Cabin**
    Número de cabina (String).

**Embarked**
    Puerto en el que embarco el pasajero. C = Cherbourg, Q = Queenstown, S = Southampton (String).


Observamos que muchas de estas variables se presentan como Integers o Strings, cuando realmente nos expresan una categoria. Por ello factorizaremos las variables categoricas.

```{r}
df$Survived <- factor(df$Survived)
df$Pclass <- factor(df$Pclass)
df$Sex <- factor(df$Sex)
df$SibSp <- factor(df$SibSp)
df$Parch <- factor(df$Parch)
df$Embarked <- factor(df$Embarked)
```


### 1.3 Motivación del estudio

Cuando el Titanic fue construido, se considero que este era imposible de hundir. Durante su viaje inaugural, el Titanic se hundió tras chocar contra un iceberg y la escasez de barcos salvavidas convirtió el accidente en una gran tragedia que resultó en la muerte de 1502 personas del conjunto de 2224 pasajeros y tripulación. Claramente la suerte tuvo un papel importante en determinar quien sobrevivió y quien no, pero se puede intuir que ciertos grupos de personas tuvieron más probabilidades de hacerlo que otros. 

En este estudio nos centraremos en responder a la pregunta "Que grupos de personas tuvieron más probabilidades de sobrevivir el accidente?". O dicho de otra forma, "¿Cuales fueron los factores de peso que influyeron en que los pasajeros tuvieran mayor probabilidad de sobrevivir?".


## Ejercicio 2

Integración y selección de los datos de interés a analizar. Puede ser el resultado de
adicionar diferentes datasets o una subselección útil de los datos originales, en base al
objetivo que se quiera conseguir.


La principal variable a incluir va a ser **Survived**. Esta será nuestra variable objetivo a estudiar ya que queremos determinar que factores tuvieron más peso al aumentar la probabilidad de sobrevivir de los pasajeros.
A continuación querremos seleccionar todas las variables que puedan describir el pasajero, y eliminar las variables irrelevantes. Observando la previa descripción de las variables realizada en el ejercicio 1, rápidamente podemos identificar que las variables **Cabin**, el número de cabina, y **Ticket**, el número del billete, no nos aportan información relevante para describir el pasajero. De mismo modo, las variables **Nombre** y **PassangerId** que sirven para identificar a los pasajeros, tampoco nos aportan información descriptiva sobre ellos.

Procedemos a descartar las variables irrelevantes.

```{r}
irrelevant <- c("Cabin", "Ticket", "Name", "PassengerId")
titanic <- df[ , -which(names(df) %in% irrelevant)]
```


## Ejercicio 3

Limpieza de los datos.

### 3.1 Valores vacios

¿Los datos contienen ceros o elementos vacíos? Gestiona cada uno de estos casos.


Estadísticas de valores vacíos.

```{r}
colSums(is.na(titanic))
colSums(titanic=="")
```

Observamos 177 valores vacíos en la variable **Age** y 2 valores vacíos en la variable **Embarked**.



Si nos centramos en el caso de la variable **Age**, esta contiene 177 valores vacíos. Como eliminar 177 observaciones del conjunto de datos supondría una gran perdida de información ya que este contiene 801 observaciones, optaremos por la estrategia de completar los valores vacíos usando la media de edad del conjunto de datos. 

```{r}
titanic$Age[is.na(titanic$Age)] <- mean(titanic$Age, na.rm=T)
```


Debido a que la variable **Embarked** tiene solo 2 valores vacíos, no vemos la necesidad de crear una categoría nueva "Desconocido" para substituir los valores vacíos, creemos que la mejor estrategia en este caso, es substituir estos valores vacíos por la categoría más repetida, evitando así la perdida de información que supondría eliminar las observaciones.

```{r}
# Determinamos la categoría que se repite con mayor frecuencia
table(titanic$Embarked)
```

Observamos que la categoría 'S' es la que se repite con mayor frecuencia.

Procedemos a sustituir los valores vacíos por 'S'.

```{r}
titanic$Embarked[titanic$Embarked == ""] <- "S"
```


Comprobamos que ya no existen valores vacíos en el conjunto de datos.
```{r}
colSums(is.na(titanic))
colSums(titanic=="")
```


### 3.2 Valores extremos

Identifica y gestiona los valores extremos.

Los valores extremos se dan en las variables continuas cuando observamos valores significativamente altos o significativamente bajos, que generan duda sobre su veracidad. 

Observemos las estadísticas básicas del conjunto de datos para identificar posibles valores extremos (*outliers*) en las variables continuas **Age**, **SibSp**, **Parch** y **Fare**.

```{r}
summary(titanic)
```

Observamos que los valores mínimos y máximos de la variable **Age**, se mantienen dentro de un rango lógico. **SibSp** y **Parch**, tienen un valor máximo alto, pero parece consistente con los estándares de familias de la época. La variable que será necesaria analizar con profundidad es **Fare**. Esta variable contiene un valor máximo muy superior al valor medio.


Utilizaremos la representación *boxplot* para identificar los *outliers* de **Fare**.

```{r}
ggplot(titanic) +
  aes(x = "", y = Fare) +
  geom_boxplot(fill = "#0c4c8a") +
  theme_minimal()
```

Con esta representación, podemos identificar claramente *outilers* correspondientes al valor máximo de 512.33. Optaremos por eliminar estos *outliers* ya que la diferencia respecto a las demás observaciones es tan significativa que sospechamos que tales observaciones contienen información no verídica. Los otros puntos que son detectados como *outliers*, menores a 300, corresponden a los precios pagados por los pasajeros de primera clase. A continuación mostramos algunas de estas observaciones para **Fare** mayor a 100.

```{r}
head(titanic[titanic$Fare > 150, ])
```


Observamos que efectivamente, esas observaciones corresponden a pasajeros de primera clase.

Eliminamos los *outliers* detectados:
```{r}
titanic <- subset(titanic, titanic$Fare < 500)
```



## Ejercicio 4

Análisis de los datos.


### 4.1 Elección de los datos a analizar

En este análisis pretendemos analizar el peso de las distintas variables del conjunto sobre la variable dependiente **Survived**. En el Ejercicio 2 escogimos el subset del conjunto de datos que consideramos de interés analítico para el estudio. Este consiste de las variables **Survived**, **Pclass**, **Sex**, **Age**, **SibSp**, **Parch**, **Fare** y **Embarked**.

De las variables de interés para el análisis, seleccionaremos ciertas agrupaciones que nos resultan interesantes de analizar en más profundidad. 
Estas serán la agrupación por genero, la variable **Sex**, y la agrupación por clase socio económica, la variable **Pclass**.

```{r}
# Agrupación por género
titanic.men   <- subset(titanic, Sex == "male")
titanic.women <- subset(titanic, Sex == "female")

# Agrupación por clase socio económica
titanic.high  <- subset(titanic, Pclass == "1")
titanic.mid   <- subset(titanic, Pclass == "2")
titanic.low   <- subset(titanic, Pclass == "3")
```


### 4.2  Normalidad y Homogeneidad

Comprobación de la normalidad y homogeneidad de la varianza.

Analizaremos la normalidad y la homogeniedad de la varianza para las variables continuas **Age** y **Fare**.


#### Age:

Análisis visual de normalidad:
```{r}
qqnorm(titanic$Age,main = "Normal Q-Q Plot para Age")
qqline(titanic$Age,col = "red")

#[1]
ggplot(titanic, aes(x = Age)) + 
  geom_histogram(aes(y = ..density..), bins = 30,
                 colour = 1, fill = "white") +
  geom_density(lwd = 1, colour = 4,
               fill = 4, alpha = 0.25) +
  ggtitle("Distribución y densidad de Age")
```

Para determinar que puede haber normalidad, deberíamos poder ver como la mayoría de observaciones se alinea encima de la línea roja (indica el comportamiento esperado de una variable normal) para la representación Quantil-Quantil. Este no es el caso observado para la variable **Age**. 

Si nos fijamos en el histograma de la variable con su correspondiente curva de densidad, para que hubiera normalidad, deberíamos observar una curva de densidad simétrica con forma de campana, por lo que podemos determinar que no es una variable normal. Podemos observar de la distribución, que la mayoría de pasajeros eran jóvenes de entre 20 y 30 años. 


Análisis por tests de normalidad:
```{r} 
#[2]
## Shapiro test
shapiro.test(titanic$Age)
## Jarque Bera test
jb.norm.test(titanic$Age)
## Forsini test
frosini.norm.test(titanic$Age)
```

Para los tests de normalidad Shapiro-Wilk, Jarque-Bera y Frosini, la hipótesis nula indica normalidad, mientras que la hipótesis alternativa indica que no hay normalidad. Un valor p superior al nivel de significancia ~0.05, nos indicaría que no podemos descartar la hipótesis nula de normalidad. Para todos los test probados, observamos unos valores p muy inferiores al nivel de significancia, que nos indican que no estamos frente a una variable normal.


Análisis de homogeniedad de la varianza:

```{r}
leveneTest(y = titanic$Age, group = titanic$Survived, center = "median")
```

Para evaluar la homocedasticidad, o la homogeniedad de la varianza, para la variable **Age**, debemos tener en cuenta que, como determinamos previamente, no se trata de una variable normal. Por ello, la elección del test Levene es la más conveniente siendo este menos sensible a que la ausencia de normalidad [3]. 

Hipótesis nula: Ambas varianzas son iguales. 
Hipótesis alternativa: Las varianzas son distintas entre si.

$$
\left\{
\begin{array}{ll}
H_{0}: &  \mu=\mu_0\\
H_{1}: & \mu\neq\mu_0
\end{array}
\right.
$$
Se aplica el test para la variable **Age** y se comparan las varianzas cuando esta variable es agrupada según **Survived**, la variable dependiente que queremos estudiar. Podemos observar de los resultados un valor p igual a 0.0169. Esto nos indica que debemos descartar la hipótesis nula, es decir, el hecho de que ambas varianzas sean iguales, en el caso de optar por un nivel de significancia de 0.01 o 0.001. Si optamos por un nivel de significancia de 0.05 o 0.1, no podemos descartar la hipótesis nula y por lo tanto las varianzas de ambos grupos deben considerarse iguales. 


#### Fare

Análisis visual de normalidad:
```{r}
qqnorm(titanic$Fare,main = "Normal Q-Q Plot para Fare")
qqline(titanic$Fare,col = "red")

#[1]
ggplot(titanic, aes(x = Fare)) + 
  geom_histogram(aes(y = ..density..), bins = 30,
                 colour = 1, fill = "white") +
  geom_density(lwd = 1, colour = 4,
               fill = 4, alpha = 0.25) +
  ggtitle("Distribución y densidad de Fare")
```

Observamos en el gráfico Normal Q-Q, como la mayoría de observaciones no se alinea encima de la línea roja que indica como debería comportarse una variable normal. Este gráfico nos indica que **Fare** no sigue una distribución normal. 

Al fijarnos en el histograma de la variable con su curva de densidad, vemos como la mayoría de valores se centran entre 0 y 50, con un pico pronunciado entorno a 10, y decaen casi exponencialmente. La curva de densidad no es simétrica ni tiene forma de campana. Determinamos que no se trata de una variable con distribución normal.


Análisis por tests de normalidad:
```{r} 
#[2]
## Shapiro test
shapiro.test(titanic$Fare)
## Jarque Bera test
jb.norm.test(titanic$Fare)
## Forsini test
frosini.norm.test(titanic$Fare)
```

Para los tests de normalidad Shapiro-Wilk, Jarque-Bera y Frosini, la hipótesis nula indica normalidad, mientras que la hipotesis alternativa indica que no hay normalidad. En todos ellos nos encontramos un valor p muy pequeño, inferior a todos los limites de significancia comunmente usados, por lo que debemos descartar la hipotesis nula de normalidad.


Análisis de homogeniedad de la varianza:

```{r}
leveneTest(y = titanic$Fare, group = titanic$Survived, center = "median")
```

Para evaluar la homocedasticidad, o la homogeniedad de la varianza, para la variable **Fare**, elijemos de nuevo el test Levene siendo este menos sensible a que la ausencia de normalidad [3]. 

Hipótesis nula: Ambas varianzas son iguales. 
Hipótesis alternativa: Las varianzas son distintas entre si.

$$
\left\{
\begin{array}{ll}
H_{0}: &  \mu=\mu_0\\
H_{1}: & \mu\neq\mu_0
\end{array}
\right.
$$

Observamos que al evaluar las varianzas agrupando la variable **Fare** en función de la variable dependiente **Survived**, estas son claramente diferentes entre ellas. Obtenemos un valor p muy pequeño, inferior a todos los límites de significancia comúnmente usados, y por ello debemos descartar las hipótesis nula. 


### 4.3 Análisis

Aplicación de pruebas estadísticas para comparar los grupos de datos. En función de los datos y el objetivo del estudio, aplicar pruebas de contraste de hipótesis, correlaciones, regresiones, etc. Aplicar al menos tres métodos de análisis diferentes.


#TODO mostraremos sus distribuciones para poder analizar si el conjunto de datos se encuentra muy desbalanceado, de forma que nos conduzca a conclusiones erróneas. 






En primer lugar, se utiliza un test Chi-cuadrado de Pearson para comprobar si existe relación entre las variables categóricas **Survive**, **Sex** y **Pclass**.

```{r}
with(titanic, chisq.test(Survived, Sex))
```

```{r}
with(titanic, chisq.test(Survived, Pclass))
```

Como en ambos casos el p-valor es menor que el nivel de significancia, se entiende que sí que existe relación.

Para estudiar si existe relación entre la variable **Age** y la variable **Survived**, se crea un modelo de regresión logística.

```{r}
model <- glm(Survived ~ Age, family = binomial(link=logit), data=titanic)
cat("The p-value is", 1-pchisq(sum(residuals(model,type="pearson")^2),1))
```

Existe relción ya que el p-valor es menor que el nivel de significancia.

A continuación, se calculará el Odds-Ratio de la variable **Survived** para cada una de las variables categóricas. El OR es un número que permite conocer cómo varía la probabilidad de que la variable dependiente adquiera un valor en función del valor que adquiera la variable independiente. Para calcularlo se crea una función.

Se calcularán los OR de sobrevivir frente a no sobrevivir.

```{r}
# Se muestra la tabla de frecuencia
print(table(titanic$Survived, titanic$Pclass), rownames(c("Not survived", "Survived")))

# Se calculan los diferentes Odds-Ratios
a <- as.data.frame(table(titanic$Survived, titanic$Pclass))
odds.high.class <- a[2,]$Freq  / a[1,]$Freq
cat("\nThe odds for the high class is ", odds.high.class, "\n")
odds.medium.class <- a[4,]$Freq  / a[3,]$Freq
cat("The odds for the medium class is ", odds.medium.class, "\n")
odds.low.class <- a[6,]$Freq  / a[5,]$Freq
cat("The odds for the low class is ", odds.low.class, "\n\n")

cat("The OR between the high class and the low class was", odds.high.class / odds.low.class, "\n")
cat("The OR between the medium class and the low class was", odds.medium.class / odds.low.class, "\n")
cat("The OR between the high class and the medium class was", odds.high.class / odds.medium.class, "\n")
```

Analizándo los resultados, una persona de clase alta tenía 5,19 veces más probabilidades de sobrevivir que una persona de clase baja.

Una persona de clase media tenía casi el triple de probabilidades de sobrevivir que una persona de clase baja.

Una persona de clase alta tenía casi el doble de probabilidades de sobrevivir que una persona de clase media.

A continuación se calcularán los OR de la variable **Sex**.

```{r}
# Se muestra la tabla de frecuencia
print(table(titanic$Survived, titanic$Sex), rownames(c("Not survived", "Survived")))

# Se calculan los diferentes Odds-Ratios
a <- as.data.frame(table(titanic$Survived, titanic$Sex))
odds.female <- a[2,]$Freq  / a[1,]$Freq
cat("\nThe odds for the female is ", odds.female, "\n")
odds.male <- a[4,]$Freq  / a[3,]$Freq
cat("The odds for the male is ", odds.male, "\n")

cat("The OR between the female and the male was", odds.female / odds.male, "\n")
```

Una mujer tenía 12,5 veces más probabilidades de sobrevivir que un hombre.


```{r}
model.age <- glm(Survived ~ Age, family = binomial(link=logit), data=titanic)
summary(model.age)
```

Se aprecia cómo el p-valor de la variable edad es mayor que 


### Comparación de las edades en los sexos

Nos preguntamos si la media de edad de hombres es mayor que la de las mujeres.

#### Análisis visual

```{r}
ggplot(data=women, mapping= aes(x=Age)) + geom_density() + scale_x_continuous("Women's age distribution") + ggtitle("Women's age")
```

```{r}
shapiro.test(women$Age)
```


```{r}
ggplot(data=men, mapping= aes(x=Age)) + geom_density() + scale_x_continuous("Men's age distribution") + ggtitle("Men's age")
```

????Aunque las muestras no presentan distribuciones normales, aplicando el Teorema del Límite Central se puede concluir que las medias muestrales siguen una distribución normal

Hipótesis nula: $H_{0}: \mu_W=\mu_M$

Hipótesis alternativa: $H_{1}: \mu_W<\mu_M$


????Es un test paramétrico ya que los datos siguen una distribución normal.

El test de contraste que se aplicará en este caso es el de un contrate unilateral de dos muestras independientes sobre la media con varianzas desconocidas. Para saber si las varianzas son diferentes, se debe realizar un test de homoscedasticidad.

```{r}
var.test(women$Age, men$Age)
```

Como el p-valor es tan alto, no se puede rechazar la hipótesis nula de que las varianzas son diferentes, por lo tanto el test seguirá una distribución *t-student* con $n_1+n_2-2$ grados de libertad.

```{r}
t.test(women$Age, men$Age, alternative = "l", var.equal = TRUE)
```

Como el p-valor es menor que el nivel de significancia, se rechaza la hipótesis nula y se acepta que la media de edad de las mujeres fue menor que la de los hombres.


### Modelo de regresión logística

A continuación se irán añadiendo variables independientes al modelo de regresión logística para tratar de obtener el modelo que mejor prediga el dataset test.

En primer lugar, se divide el dataset en un dataset de train y otro de test para evaluar los modelos. Se selecciona las proporción 1 a 4.

```{r}

set.seed(23)

trainIndex=createDataPartition(titanic$Survived, p=0.75)$Resample1

titanic_train=titanic[trainIndex, ]
titanic_test= titanic[-trainIndex, ]

cat("The train set has", nrow(titanic_train), "rows\n\n")
cat("The train set has", nrow(titanic_test), "rows")
```


Para evaluar los modelos, se crea el siguiente código: se genera una predicción de la probabilidad, se establece 0 o 1 en función de la probabilidad obtenida estableciendo el umbral en 0,5.

Finalmente, se calcula la precisión del modelo.

El primer modelo tan solo incluye la variable **Age**.

```{r}
titanic_test$pred <- predict(model.age, titanic_test, type = "response")
titanic_test$pred_d <- ifelse(titanic_test$pred < 0.5, 0, 1)
titanic_test$is_ok <- ifelse(titanic_test$Survived == titanic_test$pred_d, 1, 0)
accuracy.age <- sum(titanic_test$is_ok)/nrow(titanic_test)
cat("The accuracy of the model is ", accuracy.age)
```


Se añade la variable **Pclass**.

```{r}
model.age.Pclass <- glm(Survived ~ Age + Pclass, family = binomial(link=logit), data=titanic)
summary(model.age.Pclass)
titanic_test$pred <- predict(model.age.Pclass, titanic_test, type = "response")
titanic_test$pred_d <- ifelse(titanic_test$pred < 0.5, 0, 1)
titanic_test$is_ok <- ifelse(titanic_test$Survived == titanic_test$pred_d, 1, 0)
accuracy.age.Pclass <- sum(titanic_test$is_ok)/nrow(titanic_test)
cat("The accuracy of the model is ", accuracy.age.Pclass)
```


Se observa como la precisión aumenta hasta un 10%.


A continuación, se añade al modelo anterior la interacción entre las variables **Age** y **Pclas**.

```{r}
model.age.Pclass.in <- glm(Survived ~ Age * Pclass, family = binomial(link=logit), data=titanic)
summary(model.age.Pclass.in)
titanic_test$pred <- predict(model.age.Pclass.in, titanic_test, type = "response")
titanic_test$pred_d <- ifelse(titanic_test$pred < 0.5, 0, 1)
titanic_test$is_ok <- ifelse(titanic_test$Survived == titanic_test$pred_d, 1, 0)
accuracy.age.Pclass.in <- sum(titanic_test$is_ok)/nrow(titanic_test)
cat("The accuracy of the model is ", accuracy.age.Pclass.in)
```

A pesar de que varios términos no resultan significativos, la precisión del modelo aumenta ligeramente.


Se procederá de igual forma con el resto de variables disponbles, en un primer modelo se añadirá la variable sin interacción y a continuación con interacción.

Variable **Sex**.

```{r}
model.age.Pclass.Sex <- glm(Survived ~ Age + Pclass + Sex, family = binomial(link=logit), data=titanic)
summary(model.age.Pclass.Sex)
titanic_test$pred <- predict(model.age.Pclass.Sex, titanic_test, type = "response")
titanic_test$pred_d <- ifelse(titanic_test$pred < 0.5, 0, 1)
titanic_test$is_ok <- ifelse(titanic_test$Survived == titanic_test$pred_d, 1, 0)
accuracy.age.Pclass.Sex <- sum(titanic_test$is_ok)/nrow(titanic_test)
cat("The accuracy of the model is ", accuracy.age.Pclass.Sex)
```


Variable **Sex** con interacciones.

```{r}
model.age.Pclass.Sex.in <- glm(Survived ~ Age * Pclass * Sex, family = binomial(link=logit), data=titanic)
summary(model.age.Pclass.Sex.in)
titanic_test$pred <- predict(model.age.Pclass.Sex.in, titanic_test, type = "response")
titanic_test$pred_d <- ifelse(titanic_test$pred < 0.5, 0, 1)
titanic_test$is_ok <- ifelse(titanic_test$Survived == titanic_test$pred_d, 1, 0)
accuracy.age.Pclass.Sex.in <- sum(titanic_test$is_ok)/nrow(titanic_test)
cat("The accuracy of the model is ", accuracy.age.Pclass.Sex.in)
```

Ocurre lo mismo que con la variable anterior, aunque los términos de interacción no sean significativos, la precisión del modelo aumenta.

Variable **SibSp**.

```{r}
model.age.Pclass.Sex.SibSp <- glm(Survived ~ Age + Pclass + Sex + SibSp, family = binomial(link=logit), data=titanic)
summary(model.age.Pclass.Sex.SibSp)
titanic_test$pred <- predict(model.age.Pclass.Sex.SibSp, titanic_test, type = "response")
titanic_test$pred_d <- ifelse(titanic_test$pred < 0.5, 0, 1)
titanic_test$is_ok <- ifelse(titanic_test$Survived == titanic_test$pred_d, 1, 0)
accuracy.age.Pclass.Sex.SibSp <- sum(titanic_test$is_ok)/nrow(titanic_test)
cat("The accuracy of the model is ", accuracy.age.Pclass.Sex.SibSp)
```


Variable **SibSp** con interacción.

```{r}
model.age.Pclass.Sex.SibSp.in <- glm(Survived ~ Age * Pclass * Sex * SibSp, family = binomial(link=logit), data=titanic)
summary(model.age.Pclass.Sex.SibSp.in)
titanic_test$pred <- predict(model.age.Pclass.Sex.SibSp.in, titanic_test, type = "response")
titanic_test$pred_d <- ifelse(titanic_test$pred < 0.5, 0, 1)
titanic_test$is_ok <- ifelse(titanic_test$Survived == titanic_test$pred_d, 1, 0)
accuracy.age.Pclass.Sex.SibSp.in <- sum(titanic_test$is_ok)/nrow(titanic_test)
cat("The accuracy of the model is ", accuracy.age.Pclass.Sex.SibSp.in)
```

Variable **Parch**.

```{r}
model.age.Pclass.Sex.SibSp.Parch <- glm(Survived ~ Age + Pclass + Sex + SibSp + Parch, family = binomial(link=logit), data=titanic)
summary(model.age.Pclass.Sex.SibSp.Parch)
titanic_test$pred <- predict(model.age.Pclass.Sex.SibSp.Parch, titanic_test, type = "response")
titanic_test$pred_d <- ifelse(titanic_test$pred < 0.5, 0, 1)
titanic_test$is_ok <- ifelse(titanic_test$Survived == titanic_test$pred_d, 1, 0)
accuracy.age.Pclass.Sex.SibSp.Parch <- sum(titanic_test$is_ok)/nrow(titanic_test)
cat("The accuracy of the model is ", accuracy.age.Pclass.Sex.SibSp.Parch)
```

Variable **Parch** con interacción. Se evita imprimir el resumen del modelo ya que hay gran cantidad de términos.

```{r}
model.age.Pclass.Sex.SibSp.Parch.in <- glm(Survived ~ Age * Pclass * Sex * SibSp * Parch, family = binomial(link=logit), data=titanic)
#summary(model.age.Pclass.Sex.SibSp.Parch.in)
titanic_test$pred <- predict(model.age.Pclass.Sex.SibSp.Parch.in, titanic_test, type = "response")
titanic_test$pred_d <- ifelse(titanic_test$pred < 0.5, 0, 1)
titanic_test$is_ok <- ifelse(titanic_test$Survived == titanic_test$pred_d, 1, 0)
accuracy.age.Pclass.Sex.SibSp.Parch.in <- sum(titanic_test$is_ok)/nrow(titanic_test)
cat("The accuracy of the model is ", accuracy.age.Pclass.Sex.SibSp.Parch.in)
```

Variable **Fare**.

```{r}
model.age.Pclass.Sex.SibSp.Parch.Fare <- glm(Survived ~ Age + Pclass + Sex + SibSp + Parch + Fare, family = binomial(link=logit), data=titanic)
summary(model.age.Pclass.Sex.SibSp.Parch.Fare)
titanic_test$pred <- predict(model.age.Pclass.Sex.SibSp.Parch.Fare, titanic_test, type = "response")
titanic_test$pred_d <- ifelse(titanic_test$pred < 0.5, 0, 1)
titanic_test$is_ok <- ifelse(titanic_test$Survived == titanic_test$pred_d, 1, 0)
accuracy.age.Pclass.Sex.SibSp.Parch.Fare <- sum(titanic_test$is_ok)/nrow(titanic_test)
cat("The accuracy of the model is ", accuracy.age.Pclass.Sex.SibSp.Parch.Fare)
```

Variable **Fare** con interacciones.

```{r}
model.age.Pclass.Sex.SibSp.Parch.Fare.in <- glm(Survived ~ Age * Pclass * Sex * SibSp * Parch * Fare, family = binomial(link=logit), data=titanic)
#summary(model.age.Pclass.Sex.SibSp.Parch.Fare.in)
titanic_test$pred <- predict(model.age.Pclass.Sex.SibSp.Parch.Fare.in, titanic_test, type = "response")
titanic_test$pred_d <- ifelse(titanic_test$pred < 0.5, 0, 1)
titanic_test$is_ok <- ifelse(titanic_test$Survived == titanic_test$pred_d, 1, 0)
accuracy.age.Pclass.Sex.SibSp.Parch.Fare.in <- sum(titanic_test$is_ok)/nrow(titanic_test)
cat("The accuracy of the model is ", accuracy.age.Pclass.Sex.SibSp.Parch.Fare.in)
```

En este caso la precisión del modelo decae, por lo que se excluye la variable **Fare**.


Variable **Embarked**.

```{r}
model.age.Pclass.Sex.SibSp.Parch.Embarked <- glm(Survived ~ Age + Pclass + Sex + SibSp + Parch + Embarked, family = binomial(link=logit), data=titanic)
summary(model.age.Pclass.Sex.SibSp.Parch.Embarked)
titanic_test$pred <- predict(model.age.Pclass.Sex.SibSp.Parch.Embarked, titanic_test, type = "response")
titanic_test$pred_d <- ifelse(titanic_test$pred < 0.5, 0, 1)
titanic_test$is_ok <- ifelse(titanic_test$Survived == titanic_test$pred_d, 1, 0)
accuracy.age.Pclass.Sex.SibSp.Parch.Embarked <- sum(titanic_test$is_ok)/nrow(titanic_test)
cat("The accuracy of the model is ", accuracy.age.Pclass.Sex.SibSp.Parch.Embarked)
```


Variable **Embarked** con interacciones.

```{r}
model.age.Pclass.Sex.SibSp.Parch.Embarked.in <- glm(Survived ~ Age * Pclass * Sex * SibSp * Parch * Embarked, family = binomial(link=logit), data=titanic)
#summary(model.age.Pclass.Sex.SibSp.Parch.Embarked.in)
titanic_test$pred <- predict(model.age.Pclass.Sex.SibSp.Parch.Embarked.in, titanic_test, type = "response")
titanic_test$pred_d <- ifelse(titanic_test$pred < 0.5, 0, 1)
titanic_test$is_ok <- ifelse(titanic_test$Survived == titanic_test$pred_d, 1, 0)
accuracy.age.Pclass.Sex.SibSp.Parch.Embarked.in <- sum(titanic_test$is_ok)/nrow(titanic_test)
cat("The accuracy of the model is ", accuracy.age.Pclass.Sex.SibSp.Parch.Embarked.in)
```

En este caso la precisión del modelo también decae.

## Ejercicio 5

Representación de los resultados.

```{r}
models_names <- c("Age", "Adding Pclass", "Adding Sex", "Adding SibSp", "Adding Parch", "Adding Fare", "Adding Embarked")
models_accuracy <- c(accuracy.age, accuracy.age.Pclass, accuracy.age.Pclass.Sex, accuracy.age.Pclass.Sex.SibSp,  accuracy.age.Pclass.Sex.SibSp.Parch, accuracy.age.Pclass.Sex.SibSp.Parch.Fare, accuracy.age.Pclass.Sex.SibSp.Parch.Embarked)
models_accuracy_inter <- c(0 ,accuracy.age.Pclass.in, accuracy.age.Pclass.Sex.in, accuracy.age.Pclass.Sex.SibSp.in, accuracy.age.Pclass.Sex.SibSp.Parch.in, accuracy.age.Pclass.Sex.SibSp.Parch.Fare.in, accuracy.age.Pclass.Sex.SibSp.Parch.Embarked.in)
results <- data.frame(models_accuracy, models_accuracy_inter, row.names = models_names)
results
```

TODO
```{r}
#ggplot(results) + geom_point()
```


## Ejercicio 6


Resolución del problema. A partir de los resultados obtenidos, ¿cuáles son las
conclusiones? ¿Los resultados permiten responder al problema?



## Referencias


[1] Histogram with density in ggplot2 [fecha de consulta: 30/05/22] Disponible en: https://r-charts.com/distribution/histogram-density-ggplot2/ 


[2] Sigüeñas Gonzales, Manuel. Pruebas de Normalidad [fecha de publicación: 28/10/2015] [fecha de consulta: 30/05/22] Disponible en: https://rpubs.com/MSiguenas/122473  


[3] Amat Rodrigo, Joaquín. Análisis de la homogeneidad de varianza (homocedasticidad)[fecha de publicación: 01/01/2016] [fecha de consulta: 30/05/22] Disponible en: https://rpubs.com/Joaquin_AR/218466